# 1 项目简介
本项目结合TF-IDF方法，使用高斯朴素贝叶斯分类器、岭回归分类器、支持向量机，以及深度神经网络MLP，这4个机器学习模型，完成新闻文本分类任务；并有央广网新闻文本爬取代码，即本项目数据集来源。
# 2 机器学习新闻文本分类
## 2.1 jieba分词
x_train = [" ".join(jieba.lcut(i)) for i in x_train]对于每一篇新闻，使用jieba分词后，通过空格将分好的词连成一个字符串，提供给Tfidf使用。
## 2.2 TfidfVectorizer
使用Tfidf方法将文本转化为矩阵，以提供给sklearn分类器，Tfidf方法介绍如下：
1. 将各文档中每个单词的出现次数除以该文档中所有单词的总数，这些新的特征称之为词频tf。解决的问题：出现次数的统计是非常好的开始，但长的文本相对于短的文本有更高的单词平均出现次数，尽管他们可能在描述同一个主题。
2. 降低在该训练文集中的很多文档中均出现的单词的权重，从而突出那些仅在该训练文集中在一小部分文档中出现的单词的信息量。
## 2.3 sklearn机器学习
使用朴素贝叶斯、岭回归分类器、支持向量机，对新闻文本实现分类。
1. 朴素贝叶斯方法是基于贝叶斯定理的一组有监督学习算法，即“简单”地假设每对特征之间相互独立。GaussianNB实现了运用于分类的高斯朴素贝叶斯算法。
2. 岭分类器，是使用岭回归的分类器。此分类器首先将目标值转换，然后将问题视为回归任务（在多类别情况下的多输出回归）。
3. 支持向量机是一类按监督学习方式对数据进行二元分类的广义线性分类器，其决策边界是对学习样本求解的最大边距超平面。SVM使用铰链损失函数计算经验风险并在求解系统中加入了正则化项以优化结构风险，是一个具有稀疏性和稳健性的分类器。SVM可以通过核方法进行非线性分类，是常见的核学习方法之一。
## 2.4 实验源代码
```python
# 机器学习sklearn新闻文本分类
```
## 2.5 实验心得
1. 使用jieba分词后，sklearn中分类器的效果提高明显。
2. 在文本文件中执行机器学习算法，需要将文本内容转化成数值形式的特征向量，建议使用tf-idf方法，而不是词袋。
3. 对数据集，要先将其分成训练集和测试集后，再将文本内容转化成数值形式的特征向量，以便处理没有标签的文本内容。
# 3 深度学习新闻文本分类
## 3.1 MLP
人工神经网络按其模型结构大体可以分为前馈型网络（也称为多层感知机网络）和反馈型网络（也称为Hopfield网络）两大类，前者在数学上可以看作是一类大规模的非线性映射系统，后者则是一类大规模的非线性动力学系统。
## 3.2 实验源代码
```python
# 深度学习MLP新闻文本分类
```
## 3.3 实验心得
1. 神经网络损失函数的正确与否，会影响程序的正常运行。
2. 神经网络模型受数据量影响较大。
3. 数据集划分为训练集、验证集、测试集，提供给机器学习模型。
4. 神经网络模型训练时，可向其提供验证集，得到模型在验证集上的准确率。
5. Model.predict()返回的值需要通过np.argmax()转换，才能得到预测值。
# 4 新闻文本爬取
## 4.1 requests + BeautifulSoup
Requests获取网页源代码，BeautifulSoup提取网页新闻链接和新闻文本。
## 4.2 爬取新闻文本
1.根据一篇新闻的url链接，爬取新闻文本，需要使用Beautifulsoup库，找到这个网页所有的p标签。
2.爬取一个网页的新闻链接，进而获取这些链接的新闻文本，需要使用Beautifulsoup库，找到a标签的href，留下"shtml"==href[-5:]的链接。因爬取的新闻文本，有多处，连着2篇是一样的新闻文本，故做出不收集已在hrefs中新闻链接的改进。
3.爬取10个网页的新闻链接，进而获取这些链接的新闻文本
，这需要遍历10个网页链接。但爬取的部分新闻文本中，部分新闻出现乱码；部分新闻链接不完整；存在空格、Tab、换行等空白字符。添加encoding="utf-8"后，未解决问题；考虑到工作量，去掉了不正常的新闻链接，保存的全都是新闻文本了。
`
def get_html_text(url):
    except Exception as e:
        return url
def get_newses(url, newses):
    for href in hrefs:
        html = get_html_text(href)
        if html == href:
            continue
`
为完成机器学习任务新闻文本分类，为获取的新闻加标签；将新闻文本中的换行符去掉，使用s = "".join(s.split("\n"))。
## 4.3 实验源代码
```python
# 新闻文本爬取
```
## 4.4 实验心得
1. 解析包含所有新闻链接的网页这一步，确定仅提取新闻链接，而不提取新闻标题很重要，这样可以避免对于一篇新闻，没有提取到其新闻标题或其新闻链接。
2. 新闻标题，要从包含整篇新闻内容的网页中获取，这样提取容易很多。
3. 需要编写解析新闻文本网页的函数，编写解析包含所有新闻链接的网页的函数，编写获取1个类别下全部新闻文本的函数，也要编写遍历新闻类别链接获取10个类别新闻的全部新闻文本的主函数。
